{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Variable Elimination to approximate probability queries from a Bayesian Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from calculations_helper import disect_trees, handle_dag_variable_elimination, join_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_variable_elimination(queries: list[int], evidence: dict[int,bool], entire_network: dict) -> tuple[list[int], np.array]:\n",
    "    \"\"\"Given a Bayesian network and a list of query and evidence variables, return the probability distribution for all possible values of query variables\n",
    "\n",
    "    Args:\n",
    "        queries (list[int]): list of variables specified whose value probabilities we want to query\n",
    "        evidence (list[tuple[int,bool]]): list of variables whose values are specified and hence affect query probabilities\n",
    "        network (dict): underlying network which reveals probabilities of each node given its parents' values\n",
    "\n",
    "    Returns:\n",
    "        tuple[list[int],np.array]: probability distribution of possible combination values of each of the query variables (2^{#query variables}, 0 is all false and 2^{#query variables}-1 is all true)\n",
    "    \"\"\"\n",
    "    # if given a polytree, break it up into different trees\n",
    "    dag_map = disect_trees(entire_network)\n",
    "    # map of each dag index to all of its query and evidence variables\n",
    "    query_collections = {} \n",
    "    evidence_collections = {}\n",
    "    for i, dag in dag_map.items():\n",
    "        query_collections[i] = []\n",
    "        evidence_collections[i] = []\n",
    "        for v in queries:\n",
    "            if str(v) in dag.keys():\n",
    "                query_collections[i].append(v)\n",
    "        for v in evidence.keys():\n",
    "            if str(v) in dag.keys():\n",
    "                evidence_collections[i].append(v)\n",
    "        # we'll sort the variables, which will affect the value order in the soon-to-be-calulated probability distributions\n",
    "        query_collections[i].sort()\n",
    "    \n",
    "    if len(dag_map) == 1:\n",
    "        # only one directed acyclic graph\n",
    "        return queries, handle_dag_variable_elimination(entire_network, queries, evidence)\n",
    "    else:\n",
    "        # each directed acyclic graph will output a probability distribution - we must join them all and keep track of the variables present\n",
    "        reordered_queries = []\n",
    "        prob_distributions = []\n",
    "        for i, dag in dag_map.items():\n",
    "            these_queries = query_collections[i]\n",
    "            for v in these_queries:\n",
    "                reordered_queries.append(v)\n",
    "            this_evidence = {v:evidence[v] for v in evidence_collections[i]}\n",
    "            prob_distributions.append(handle_dag_variable_elimination(dag, these_queries, this_evidence))\n",
    "        return reordered_queries, join_distributions(prob_distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0], array([0.71582816, 0.28417184]))\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "queries = [0]\n",
    "evidence = {3:True,4:True}\n",
    "\n",
    "with open('bn_test_1.json') as f:\n",
    "    bayesian_network = json.load(f)\n",
    "    print(estimate_variable_elimination(queries, evidence, bayesian_network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 3], array([0.34953879, 0.056898  , 0.10097538, 0.49258784]))\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "queries = [0, 3]\n",
    "evidence = {2:True}\n",
    "\n",
    "with open('bn_test_2.json') as f:\n",
    "    bayesian_network = json.load(f)\n",
    "    print(estimate_variable_elimination(queries, evidence, bayesian_network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1], array([0.87746479, 0.12253521]))\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "queries = [1]\n",
    "evidence = {2:False}\n",
    "\n",
    "with open('bn_test_3.json') as f:\n",
    "    bayesian_network = json.load(f)\n",
    "    print(estimate_variable_elimination(queries, evidence, bayesian_network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmall_polytree.json\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      7\u001b[0m     bayesian_network \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mestimate_variable_elimination\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevidence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbayesian_network\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[3], line 41\u001b[0m, in \u001b[0;36mestimate_variable_elimination\u001b[0;34m(queries, evidence, entire_network)\u001b[0m\n\u001b[1;32m     39\u001b[0m         reordered_queries\u001b[38;5;241m.\u001b[39mappend(v)\n\u001b[1;32m     40\u001b[0m     this_evidence \u001b[38;5;241m=\u001b[39m {v:evidence[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m evidence_collections[i]}\n\u001b[0;32m---> 41\u001b[0m     prob_distributions\u001b[38;5;241m.\u001b[39mappend(\u001b[43mhandle_dag_variable_elimination\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthese_queries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis_evidence\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reordered_queries, join_distributions(prob_distributions)\n",
      "File \u001b[0;32m~/Developer/Bayesian-Network/calculations_helper.py:424\u001b[0m, in \u001b[0;36mhandle_dag_variable_elimination\u001b[0;34m(dag, queries, evidence)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Helper method to compute variable elimination when only dealing with a directed acyclic graph and not a polytree\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \n\u001b[1;32m    415\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;124;03m    np.array: probability distribution pertaining to the query variable values\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;66;03m# grab the list of factors and each factor has its own probability distribution - which will depend on its parents should they exist\u001b[39;00m\n\u001b[0;32m--> 424\u001b[0m factor_index_to_factor, var_to_factor_indices \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_factors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevidence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;66;03m# ultimately, factors will be merged, and thus their index will correspond to the same set variable - we do not want that showing up multiple times when we consider the relevant factors to a variable below\u001b[39;00m\n\u001b[1;32m    427\u001b[0m factor_tracker \u001b[38;5;241m=\u001b[39m DisjointSetCollection()\n",
      "File \u001b[0;32m~/Developer/Bayesian-Network/calculations_helper.py:269\u001b[0m, in \u001b[0;36mcreate_factors\u001b[0;34m(network, evidence)\u001b[0m\n\u001b[1;32m    267\u001b[0m     prob_tuple \u001b[38;5;241m=\u001b[39m ([parent \u001b[38;5;28;01mfor\u001b[39;00m parent \u001b[38;5;129;01min\u001b[39;00m parents_not_in_evidence] \u001b[38;5;241m+\u001b[39m ([i] \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m evidence\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01melse\u001b[39;00m []), final_prob_array)\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m prob_tuple[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 269\u001b[0m         \u001b[43mvar_to_factor_indices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mlen\u001b[39m(factor_index_to_factor))\n\u001b[1;32m    270\u001b[0m     factor_index_to_factor[\u001b[38;5;28mlen\u001b[39m(factor_index_to_factor)] \u001b[38;5;241m=\u001b[39m prob_tuple\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m factor_index_to_factor, var_to_factor_indices\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "queries = [1, 3]\n",
    "evidence = {2:False, 5:True}\n",
    "\n",
    "with open('small_polytree.json') as f:\n",
    "    bayesian_network = json.load(f)\n",
    "    print(estimate_variable_elimination(queries, evidence, bayesian_network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbig_polytree.json\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      7\u001b[0m     bayesian_network \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mestimate_variable_elimination\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevidence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbayesian_network\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[4], line 28\u001b[0m, in \u001b[0;36mestimate_variable_elimination\u001b[0;34m(queries, evidence, network)\u001b[0m\n\u001b[1;32m     25\u001b[0m hidden_vars\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x : \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(var_to_factor_indices[x]))\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# now we go through and eliminate each hidden variable\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[43mhandle_vars\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meliminate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor_index_to_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfactor_index_to_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor_tracker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfactor_tracker\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvar_to_factor_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar_to_factor_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m result \u001b[38;5;241m=\u001b[39m handle_vars(\u001b[38;5;28mvars\u001b[39m\u001b[38;5;241m=\u001b[39mqueries, eliminate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, factor_index_to_factor\u001b[38;5;241m=\u001b[39mfactor_index_to_factor, factor_tracker\u001b[38;5;241m=\u001b[39mfactor_tracker,var_to_factor_indices\u001b[38;5;241m=\u001b[39mvar_to_factor_indices) \u001b[38;5;66;03m# this function also returns a factor\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(result)\n",
      "File \u001b[0;32m~/Developer/Bayesian-Network/calculations_helper.py:206\u001b[0m, in \u001b[0;36mhandle_vars\u001b[0;34m(vars, eliminate, factor_index_to_factor, factor_tracker, var_to_factor_indices)\u001b[0m\n\u001b[1;32m    204\u001b[0m unique_factor_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([factor_tracker\u001b[38;5;241m.\u001b[39mget(f_idx) \u001b[38;5;28;01mfor\u001b[39;00m f_idx \u001b[38;5;129;01min\u001b[39;00m var_to_factor_indices[var]])\n\u001b[1;32m    205\u001b[0m unique_factors \u001b[38;5;241m=\u001b[39m [factor_index_to_factor[f_idx] \u001b[38;5;28;01mfor\u001b[39;00m f_idx \u001b[38;5;129;01min\u001b[39;00m unique_factor_indices]\n\u001b[0;32m--> 206\u001b[0m resulting_vars, array \u001b[38;5;241m=\u001b[39m \u001b[43mjoin_factors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meliminate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meliminate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelevant_factors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munique_factors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m join_base \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# Factors are now merged - so update factor tracker accordingly\u001b[39;00m\n",
      "File \u001b[0;32m~/Developer/Bayesian-Network/calculations_helper.py:144\u001b[0m, in \u001b[0;36mjoin_factors\u001b[0;34m(var, eliminate, relevant_factors)\u001b[0m\n\u001b[1;32m    142\u001b[0m next_factor \u001b[38;5;241m=\u001b[39m relevant_factors[i]\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Find the list of rows corresponding to each factor that must multiply together\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m row_multiplications, joined_vars \u001b[38;5;241m=\u001b[39m \u001b[43mfind_common_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_factor\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_factor\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# Create a new array to populate with products\u001b[39;00m\n\u001b[1;32m    146\u001b[0m merged_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(joined_vars))\n",
      "File \u001b[0;32m~/Developer/Bayesian-Network/calculations_helper.py:109\u001b[0m, in \u001b[0;36mfind_common_rows\u001b[0;34m(prev_factor_vars, next_factor_vars)\u001b[0m\n\u001b[1;32m    107\u001b[0m         bit_mask[j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# now we have a bit mask telling us which variables will be true - find the rows for each of the two factors where this combination of truth values for the shared variables occurs\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m prev_factor_rows \u001b[38;5;241m=\u001b[39m \u001b[43mfind_corresponding_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbit_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommon_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_factor_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m next_factor_rows \u001b[38;5;241m=\u001b[39m find_corresponding_rows(bit_mask, common_vars, next_factor_vars)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prev_row \u001b[38;5;129;01min\u001b[39;00m prev_factor_rows:\n",
      "File \u001b[0;32m~/Developer/Bayesian-Network/calculations_helper.py:56\u001b[0m, in \u001b[0;36mfind_corresponding_rows\u001b[0;34m(bit_mask, common_vars, all_vars)\u001b[0m\n\u001b[1;32m     54\u001b[0m             row_sets[i]\u001b[38;5;241m.\u001b[39madd(row)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# now take the intersection of all the row sets\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mrow_sets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m     57\u001b[0m     missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(row_sets)):\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "queries = [1, 3]\n",
    "evidence = {2:False, 5:True}\n",
    "\n",
    "with open('big_polytree.json') as f:\n",
    "    bayesian_network = json.load(f)\n",
    "    print(estimate_variable_elimination(queries, evidence, bayesian_network))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
