{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Variable Elimination to approximate probability queries from a Bayesian Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given an arbitrary Bayesian Network, an arbitrary set of query variables, and arbitrary evidence, we want to be able to calculate the probability of said variable...\n",
    "import numpy as np\n",
    "\n",
    "def join(first: np.array, second: np.array, row_pairings: dict[int,list[int]]) -> np.array:\n",
    "    \"\"\"Given two distributions and the variable to to join on, join the two distributions into a third\n",
    "\n",
    "    Args:\n",
    "        first (np.ndarray): first distribution (smaller or same size)\n",
    "        second (np.ndarray): second distribution (larger or same size)\n",
    "        row_pairings (dict[int,list[int]]): map of rows of smaller first distribution mapping to rows of second distribution they will multiply\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: resulting distribution after joining\n",
    "    \"\"\"\n",
    "    result = np.zeros(second.shape)\n",
    "    for first_index, second_indices in row_pairings.items():\n",
    "        for s in second_indices:\n",
    "            result[s] += first[first_index] * second[s]\n",
    "    return result\n",
    "\n",
    "def eliminate(distribution: np.array, pairings: list[tuple[int,int]]) -> np.array:\n",
    "    \"\"\"eliminate a variable by summing over the distribution at the specified index pairs\n",
    "\n",
    "    Args:\n",
    "        distribution (np.ndarray): pairs of indices we add together\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: resulting distribution (dimensions will be half as large)\n",
    "    \"\"\"\n",
    "    result = np.array(shape=len(pairings))\n",
    "    for i, pair in enumerate(pairings):\n",
    "        result[i] = distribution[pair[0]] + distribution[pair[1]]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "distr_1 = np.array([.000999, .00029, .93906, .00095])\n",
    "distr_2 = np.array([.95,.05,.55,.45,.17,.83,.23,.77])\n",
    "joined = join(distr_1, distr_2, {0:[0,1],1:[2,3],2:[4,5],3:[6,7]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.108550e-03, 1.804500e-04, 1.598587e-01, 7.801513e-01])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eliminate(joined, pairings=[(0,2),(1,3),(4,6),(5,7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_variable(var: int, relevant_factors: list[tuple[list[int],np.array]]) -> tuple[list[int],np.array]:\n",
    "    \"\"\"Given which variable we want to eliminate, multiply its respective factors together and then sum out over the variable to eliminate\n",
    "\n",
    "    Args:\n",
    "        var (int): the variable to eliminate\n",
    "        factors (list[tuple[list[int],np.array]]): list of distributions corresponding to this variable\n",
    "\n",
    "    Returns:\n",
    "        tuple[list[int],np.array]: new list of relevant variables to this array along with the array (a new distribution)\n",
    "    \"\"\"\n",
    "    # We need to find out which rows multiply together\n",
    "    # Break into pairs\n",
    "    # TODO - revise approach and complete\n",
    "    prev_factor = relevant_factors[0]\n",
    "    for i in range(1, len(relevant_factors)):\n",
    "        next_factor = relevant_factors[i]\n",
    "        merged = None\n",
    "        # TODO - continue\n",
    "        prev_factor = merged\n",
    "\n",
    "def relevant(parents: list[int], parents_in_evidence: list[int], evidence: dict[int,bool], row: int) -> bool:\n",
    "    \"\"\"Based on the parents' order for a given probability array, which parents are in the evidence, and whether those parents are true or false, determine if the row is consistent with the evidence based on our probability array construction convention\n",
    "\n",
    "    Args:\n",
    "        parents (list[int]): list of parents in order for some probability array\n",
    "        parents_in_evidence (list[int]): list of parents which are in the evidence\n",
    "        evidence (dict[int,bool]): records which variables in the evidence are true or false\n",
    "        row (int): row index to determine if consistent with evidence\n",
    "\n",
    "    Returns:\n",
    "        bool: whether row number is consistent with evidence\n",
    "    \"\"\"\n",
    "    for parent in parents_in_evidence:\n",
    "        parent_idx = parents.index(parent)\n",
    "        binary_posn = len(parents) - 1 - parent_idx\n",
    "        switch_every = 2 ** binary_posn\n",
    "        negative_row = ((row // switch_every) % 2) == 0\n",
    "        if (negative_row and evidence[parent]) or ((not negative_row) and (not evidence[parent])):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def return_query_probabilities(queries: list[int], evidence: dict[int,bool], network: dict) -> np.array:\n",
    "    \"\"\"Given a Bayesian network and a list of query and evidence variables, return the probability distribution for all possible values of query variables\n",
    "\n",
    "    Args:\n",
    "        queries (list[int]): list of variables specified whose value probabilities we want to query\n",
    "        evidence (list[tuple[int,bool]]): list of variables whose values are specified and hence affect query probabilities\n",
    "        network (dict): underlying network which reveals probabilities of each node given its parents' values\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: probability distribution of possible combination values of each of the query variables (2^{#query variables}, 0 is all false and 2^{#query variables}-1 is all true)\n",
    "    \"\"\"\n",
    "    # we need a map of variables to their respective factors (some of which will be shared) - factors are integers serving as references to numpy arrays\n",
    "    factor_mappings = {i:[] for i in network.keys()}\n",
    "    factors = {}\n",
    "    # each factor has its own probability distribution - which may or may not depend on its parents\n",
    "    for i, info in network.items():\n",
    "        # if i is not in evidence, we have work to do\n",
    "        if i in evidence.keys():\n",
    "            continue\n",
    "\n",
    "        parents = info[\"parents\"]\n",
    "        parents_in_evidence = [p for p in parents if p in evidence.keys()]\n",
    "        parents_not_in_evidence = [p for p in parents if p not in evidence.keys()]\n",
    "        # obtain the array of probabilities before considering evidence\n",
    "        prob_array = np.array([pair[1] for pair in info[\"prob\"]])\n",
    "\n",
    "        # now filter the probability array so that it only contains entries consistent with the evidence\n",
    "        relevant_rows = []\n",
    "        for row in range(len(prob_array)):\n",
    "            if relevant(parents, parents_in_evidence, evidence, row):\n",
    "                relevant_rows.append(row)\n",
    "        # quick sanity check\n",
    "        assert len(relevant_rows) == 2 ** len(parents_not_in_evidence)\n",
    "\n",
    "        # our base array size depends on the number of parents not in our evidence (and so take on both true and false values)\n",
    "        new_prob_array = np.zeros(len(relevant_rows))\n",
    "        # fill new_prob_array with relevant rows\n",
    "        for i, row in enumerate(relevant_rows):\n",
    "            new_prob_array[i] = prob_array[row]\n",
    "\n",
    "        # double the size of our array so that it can contain the probabilities of 'i' being true and false\n",
    "        final_prob_array = np.zeros(2 * len(new_prob_array))\n",
    "        for i in range(len(prob_array)):\n",
    "            final_prob_array[2*i] = 1 - new_prob_array[i]\n",
    "            final_prob_array[2*i+1] = new_prob_array[i]\n",
    "\n",
    "        # finally store into a tuple\n",
    "        prob_tuple = ([parent for parent in parents] + [i], final_prob_array)\n",
    "        factors[len(factors)] = prob_tuple\n",
    "        # each involved variable needs THAT reference to prob_tuple\n",
    "        factor_mappings[i].append(len(factors))\n",
    "        for p in parents:\n",
    "            factor_mappings[p].append(len(factors))\n",
    "    \n",
    "    # figure out which variables need to be eliminated\n",
    "    query_set = set(queries)\n",
    "    evidence_set = set([pair[0] for pair in evidence])\n",
    "    hidden_vars = [i for i in range(len(network)) if i not in query_set and i not in evidence_set]\n",
    "    # eliminate the hidden variables in an order based on their number of factors - more factors means eliminate sooner\n",
    "    hidden_vars.sort(key=lambda i : -len(factor_mappings[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.])]\n",
      "[array([1.])]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1.0])\n",
    "lst = [a]\n",
    "print(lst)\n",
    "a = None\n",
    "print(lst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
